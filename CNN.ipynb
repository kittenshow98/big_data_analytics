{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import torch.optim\n",
    "import numpy.random\n",
    "import math\n",
    "import pandas\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.loc[:, train.columns != 'totals.transactionRevenue']\n",
    "train_y = train['totals.transactionRevenue'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.loc[:, test.columns != 'totals.transactionRevenue']\n",
    "test_y = test['totals.transactionRevenue'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_X)#np.ndarray()\n",
    "train_X_list=train_data.tolist()#list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_torch = torch.FloatTensor(train_X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.FloatTensor(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train_torch.unsqueeze(0)\n",
    "training_data = training_data.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.unsqueeze(0)\n",
    "target = target.permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(training_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import torch.optim\n",
    "import numpy.random\n",
    "import math\n",
    "import pandas\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_net(nn.Module):\n",
    "    def __init__(self,str_cols, num_cols):\n",
    "        \n",
    "        super(CNN_net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "\n",
    "            nn.Conv1d(1, 16, kernel_size=3),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.MaxPool1d(2,2),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "#             nn.MaxPool1d(2,2),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "#         self.fc3 = nn.Dropout(0.5)\n",
    "#         self.fc4 = nn.Linear((len(str_cols) + len(num_cols) - 4 ) * 32,1)\n",
    "        self.fc4 = nn.Linear(288,1)\n",
    "#         self.fc5 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        out = x.reshape(x.size(0), -1)\n",
    "#         print(out.size())\n",
    "#         out = self.fc3(out)\n",
    "        f = self.fc4(out)\n",
    "#         f = self.fc5(f)\n",
    "        return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = [\"channelGrouping\", \n",
    "            \"geoNetwork.city\", \"geoNetwork.continent\", \n",
    "            \"geoNetwork.country\", \"geoNetwork.metro\",\n",
    "            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n",
    "            \"geoNetwork.subContinent\", \"customDimensions.value\"]\n",
    "\n",
    "#num_cols = [\"year\", \"month\",\"weekday\",\"hour\",\"minute\",\"second\",\"totals.hits\", \"totals.pageviews\", \"visitNumber\", 'totals.bounces',  'totals.newVisits'] \n",
    "num_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", 'totals.bounces',  'totals.newVisits'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN_net(str_cols, num_cols)\n",
    "# net = net.cuda()\n",
    "# print(net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero the gradient buffers\n",
    "net.zero_grad()\n",
    "loss_list = []\n",
    "\n",
    "epoch = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=51e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "#     if i%100 == 0:\n",
    "    print(i)\n",
    "#     torch.cuda.empty_cache()\n",
    "    running_loss = 0\n",
    "    train_loader = data_utils.DataLoader(train, batch_size=256, shuffle=True)\n",
    "    for trainx,labelx in train_loader:\n",
    "        #print(trainx.size())\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(net(trainx), labelx)\n",
    "        loss_list.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        running_loss += float(loss.item())\n",
    "        loss_list.append(running_loss)\n",
    "    print(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
